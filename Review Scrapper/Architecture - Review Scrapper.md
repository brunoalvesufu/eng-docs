# üëÄ¬†Problema

- Filmes, s√©ries e jogos recebem notas de analistas, que por sua vez s√£o compiladas em v√°rios sites.
- Tanto a opini√£o de um cr√≠tico em espec√≠fico, como a nota m√©dia de todos os cr√≠ticos, s√£o importantes na tomada de decis√£o do que consumir.
- Navegar por todos esses sites consome tempo, al√©m de ser confuso em alguns casos.

---

# üí≠¬†Proposta

- Proponho um sistema que fa√ßa o scrapping desses sites e reporte as notas ao usu√°rio baseado em algumas regras, como: cr√≠tico espec√≠fico, g√™nero espec√≠fico, diretor ou atores envolvidos, empresa respons√°vel, etc.
- O sistema n√£o envia an√°lises em que a nota √© menor que 80.
- A princ√≠pio, o sistema receber√° o link do site a realizar o scrapping e o email para onde o report ser√° enviado.
- A primeira vers√£o far√° o scrapping apenas do site Opencritic, especificamente das notas dadas pelo [Metro Game Central](https://opencritic.com/outlet/75/metro-gamecentral).
- O futuro do projeto dever√° contemplar outras p√°ginas do site Opencritic, al√©m dos sites Metacritic, Rotten Tomatoes e IMDB.
- A implementa√ß√£o do c√≥digo deve contemplar Inje√ß√£o de Depend√™ncia, onde apenas o m√≥dulo para um site espec√≠fica precisar√° ser desenvolvido. M√©todos como fetchWeb, fetchDB e sendReport ser√£o diferentes para cada ambiente.
- Haver√° uma p√°gina wed dispon√≠vel para que o usu√°rio insira seu nome, e-mail e site a ser varrido.
- O sistema ir√° rodar todos os dias √†s 20h.

---

# üõ´¬†Plano

- O sistema ser√° desenvolvido em Typescript, usando arquitetura hexagonal.
    
- O sistema ter√° quatro m√≥dulos principais, colocados em um √∫nico reposit√≥rio e separado por diret√≥rios.
    
- Em uma segunda vers√£o, os m√≥dulos ser√£o convertidos em micro-servi√ßos com comunica√ß√£o por Kafka.
    
- Os m√≥dulos s√£o:
    
    - fetch: busca os elementos na web e os salva sem an√°lise em uma tabela SQL chamada **elementsDB (elemHash, page, element);**
    - scrape: extrai as informa√ß√µes relevantes dos elementos da tabela elements e as salva em outra tabela chamada **reviewsDB (elemHash, title, grade, grade2, description, source);**
    - request: endpoint onde o usu√°rio passa suas informa√ß√µes e requisita a gera√ß√£o de um novo report, os usu√°rios ser√£o salvos na tabela **usersDB (userID, name, email)**, suas requisi√ß√µes ser√£o salvas na tabela **requestsDB (requestID, page, users_ids[userID], lastElemHash);**
    - report: monta os relat√≥rios e os envia aos usu√°rios.
    
    ```mermaid
    flowchart TD
      user((user)) <-->|system endpoint| request
      request -->|store request| requestsDB[("requestsDB")]
      request -->|store user| usersDB[("usersDB")]
      Trigger_at_8pm --> fetch
      requestsDB -->|fetch page| fetch 
      fetch <-->|HTTP| website("website")
      fetch -->|store elements| elementsDB[("elementsDB")]
      fetch -->|elements_ids| scrape
      elementsDB[("elementsDB")]-->|fetch elements| scrape 
      scrape -->|stores reviews| reviewsDB[("reviewsDB")]
      scrape -->|elements_ids| report
    	reviewsDB[("reviewsDB")] -->|fetch_reviews| report
    	elementsDB -->|fetch pages| report
    	usersDB -->|fetch users| report
    	report -->|e-mail| user((user))
    ```
    

1. usu√°rio acessa a p√°gina de cadastro (disponibilizada por request) e informa nome, e-mail e p√°gina a ser varrida;
2. request salva as informa√ß√µes do usu√°rio em usersDB e as informa√ß√µes da requisi√ß√£o em requestsDB;
3. fetch, diariamente as 8pm, busca as p√°ginas que devem ser varridas;
4. fetch, uma a uma, varre a p√°gina e:
    1. faz um diff com o hash dos elementos j√° presentes no banco (uso de hash como blindagem ao tamanho dos elementos);
    2. para varrimento de p√°ginas sequenciais, fetch avancar√° at√© encontrar o hash primeiro elemento encontrado no √∫ltimo varrimento.
5. fetch salva os novos elementos na tabela elementsDB;
6. fetch avisa ao scrape se h√° novas informa√ß√µes, passando os ids dos elementos;
7. scrape consulta os ids na tabela de elementsDB, realiza a extra√ß√£o das informa√ß√µes e as salva em reviewsDB;
8. scrape avisa ao report sobre as novas reviews, enviando os ids dos elementos;
9. report usa os ids dos elementos para consultar a p√°gina dos novos elementos em elementsDB;
10. report consulta os usu√°rios que solicitaram informa√ß√µes naquela p√°gina;
11. report usa os ids dos elementos para consultar as reviews em reviewsDB;
12. report cria o relat√≥rio usando os dados das reviews e envia ao email dos usu√°rios.

PS: O excesso de consulta e escrita do banco de dados √© proposital, com objetivo did√°tico.